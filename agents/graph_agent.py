# agents/graph_agent.py

import sys
import os
import operator
from typing import TypedDict, Annotated, List, Dict, Any

# Projenin ana dizinini Python'un yoluna ekliyoruz.
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# --- LangChain ve LangGraph KÃ¼tÃ¼phaneleri ---
from langgraph.graph import StateGraph, END
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate

# --- Proje BileÅŸenleri ---
from config import settings
from tools.architectural_tools import decide_architecture
from tools.operational_tools import find_and_prepare_gpu, start_task_on_pod
from tools.pod_management_tools import execute_command_on_pod, get_pod_status


# 1. Yeni "Beyaz Tahta" (AgentState) - Ã‡ok AdÄ±mlÄ± HafÄ±za + AkÄ±llÄ± YÃ¶nlendirme
class AgentState(TypedDict):
    input: str                          # KullanÄ±cÄ±nÄ±n orijinal gÃ¶revi
    route_decision: str                 # YÃ¶nlendirme kararÄ±: "chat" veya "task"
    plan: List[str]                     # AdÄ±mlarÄ±n planÄ± (string listesi)
    executed_steps: Annotated[List[Dict], operator.add]  # Tamamlanan adÄ±mlarÄ±n sonuÃ§larÄ±
    current_step_index: int             # Åu anki adÄ±m numarasÄ±
    final_result: str                   # Nihai cevap


# 2. Ã‡ok AdÄ±mlÄ± Proje YÃ¶neticisi SÄ±nÄ±fÄ±
class GraphAgent:
    """
    LangGraph kullanarak, Ã§ok adÄ±mlÄ± gÃ¶revleri planlayan, adÄ±m adÄ±m uygulayan
    ve hafÄ±zasÄ±nÄ± koruyan geliÅŸmiÅŸ proje yÃ¶neticisi ajanÄ±.
    """
    def __init__(self):
        # LLM'i baÅŸlat
        self.llm = ChatGroq(
            temperature=0.1,  # Biraz yaratÄ±cÄ±lÄ±k iÃ§in artÄ±rdÄ±k
            model_name=settings.AGENT_MODEL_NAME,
            groq_api_key=settings.GROQ_API_KEY
        )
        
        # Alet Ã§antasÄ±nÄ± sÃ¶zlÃ¼k olarak tanÄ±mla (kolay eriÅŸim iÃ§in)
        self.tools_dict = {
            "decide_architecture": decide_architecture,
            "find_and_prepare_gpu": find_and_prepare_gpu,
            "start_task_on_pod": start_task_on_pod,  # Jupyter notebook komut hazÄ±rlama
            "execute_command_on_pod": execute_command_on_pod,  # Eski versiyon (fallback)
            "get_pod_status": get_pod_status,
            # SSH araÃ§larÄ±nÄ± ekle
            "execute_ssh_command": self._execute_ssh_command_wrapper,
        }
        
        # GrafiÄŸi oluÅŸtur
        self.graph = self.build_graph()
        print("ğŸ§  GraphAgent: Ã‡ok adÄ±mlÄ± hafÄ±za sistemi aktif!")

    def _execute_ssh_command_wrapper(self, **kwargs) -> Dict:
        """SSH komut Ã§alÄ±ÅŸtÄ±rma wrapper'Ä±."""
        try:
            from tools.ssh_pod_tools import execute_ssh_command
            pod_id = kwargs.get("pod_id", "")
            command = kwargs.get("command", "")
            
            if not pod_id or not command:
                return {"status": "error", "message": "Pod ID ve komut gerekli"}
            
            return execute_ssh_command(pod_id, command)
        except Exception as e:
            return {"status": "error", "message": f"SSH hatasÄ±: {str(e)}"}

    def _simulate_task_execution(self, **kwargs) -> Dict:
        """
        GeÃ§ici simÃ¼lasyon aracÄ± - gerÃ§ek implementasyon gelene kadar
        """
        return {
            "status": "success",
            "message": "Task simulation completed successfully",
            "details": f"Simulated execution with parameters: {kwargs}"
        }

    # === YENÄ° Ä°Å Ä°STASYONU 0: AKILLI YÃ–NLENDÄ°RÄ°CÄ° DÃœÄÃœMÃœ ===
    def route_query(self, state: AgentState) -> Dict:
        """
        KullanÄ±cÄ±nÄ±n girdisini analiz eder ve "chat" mi "task" mÄ± olduÄŸuna karar verir.
        Bu, grafiÄŸin "kapÄ±daki gÃ¼venlik gÃ¶revlisi"sidir.
        """
        print("\nğŸšª [YÃ–NLENDÄ°RÄ°CÄ°] KullanÄ±cÄ± girdisi analiz ediliyor...")
        
        routing_prompt = ChatPromptTemplate.from_messages([
            ("system", """Sen, kullanÄ±cÄ± girdilerini kategorize eden uzman bir analiz sistemisin.
            
GÃ¶revin: Verilen girdiyi analiz edip, sadece "chat" veya "task" kelimelerinden birini dÃ¶ndÃ¼rmek.

KURALLAR:
- EÄŸer girdi sadece selamlama ise -> "chat" 
- DÄ°ÄER HER ÅEY -> "task" (Pod, kod, ortam, oluÅŸtur, Ã§alÄ±ÅŸtÄ±r, yaz iÃ§eren tÃ¼m istekler)

Ã–RNEKLERÄ°:
- "merhaba" -> chat
- "nasÄ±lsÄ±n" -> chat  
- "pod oluÅŸtur" -> task
- "kod yaz" -> task
- "ortam hazÄ±rla" -> task
- "Ã§alÄ±ÅŸtÄ±r" -> task
- "GPU" -> task
- "RunPod" -> task
- "hesap makinesi" -> task

UYARI: ÅÃ¼pheli durumlarda "task" seÃ§! Pod/kod/Ã§alÄ±ÅŸtÄ±r kelimelerini gÃ¶ren her ÅŸey "task"!

SADECE "chat" veya "task" kelimesini dÃ¶ndÃ¼r, baÅŸka hiÃ§bir ÅŸey yazma!"""),
            ("user", "{input}")
        ])
        
        try:
            response = self.llm.invoke(routing_prompt.format_messages(input=state["input"]))
            decision = response.content.strip().lower()
            
            # GÃ¼venlik kontrolÃ¼ - sadece geÃ§erli deÄŸerler
            if decision not in ["chat", "task"]:
                decision = "chat"  # ÅÃ¼pheli durumlarda gÃ¼venli tarafta kal
                
            print(f"ğŸ“‹ YÃ¶nlendirme KararÄ±: '{decision}' (Girdi: '{state['input']}')")
            
            return {"route_decision": decision}
            
        except Exception as e:
            print(f"âŒ YÃ¶nlendirici hatasÄ±: {e}")
            return {"route_decision": "chat"}  # Hata durumunda gÃ¼venli mod

    # === YENÄ° Ä°Å Ä°STASYONU 1: SOHBET DÃœÄÃœMÃœ ===
    def chatbot_step(self, state: AgentState) -> Dict:
        """
        Basit sohbet iÅŸlemlerini halleder. HiÃ§bir araÃ§ kullanmaz, sadece doÄŸal sohbet.
        """
        print("\nğŸ’¬ [SOHBET DÃœÄÃœMÃœ] DoÄŸal sohbet cevabÄ± oluÅŸturuluyor...")
        
        chat_prompt = ChatPromptTemplate.from_messages([
            ("system", """Sen, AtÃ¶lye Åefi isimli, yardÄ±msever ve dostane bir AI asistanÄ±sÄ±n.
            
Ã–zelliklerin:
- MLOps ve AI konularÄ±nda uzman
- Docker, GPU, model eÄŸitimi konularÄ±nda bilgili
- SÄ±cak ve samimi bir konuÅŸma tarzÄ±n var
- TÃ¼rkÃ§e konuÅŸuyorsun

KullanÄ±cÄ±yla doÄŸal bir sohbet yap. KÄ±sa, net ve dostane cevaplar ver."""),
            ("user", "{input}")
        ])
        
        try:
            response = self.llm.invoke(chat_prompt.format_messages(input=state["input"]))
            result = response.content.strip()
            
            print(f"ğŸ’­ Sohbet CevabÄ±: {result[:100]}...")
            
            return {"final_result": result}
            
        except Exception as e:
            print(f"âŒ Sohbet hatasÄ±: {e}")
            return {"final_result": "ÃœzgÃ¼nÃ¼m, ÅŸu anda bir sorun yaÅŸÄ±yorum. Tekrar dener misin?"}

    # === Ä°Å Ä°STASYONU 2: YENÄ° PLANLAMA DÃœÄÃœMÃœ ===
    def plan_step(self, state: AgentState) -> Dict:
        """
        KullanÄ±cÄ±nÄ±n gÃ¶revini analiz eder ve her biri tek bir bash komutu olan adÄ±mlar oluÅŸturur.
        """
        print("\nğŸ¯ [PLANLAMA DÃœÄÃœMÃœ] GÃ¶rev bash komutlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
        
        planning_prompt = ChatPromptTemplate.from_messages([
            ("system", """Sen, bir DevOps otomasyon uzmanÄ±sÄ±n. Sana verilen gÃ¶revi, uzak bir sunucuda, 
            bash terminalinde Ã§alÄ±ÅŸtÄ±rÄ±lacak, TEKÄ°L VE SIRALI KOMUTLARIN bir listesine dÃ¶nÃ¼ÅŸtÃ¼r.

            KURALLAR:
            - Her adÄ±m, SADECE TEK BÄ°R KOMUT iÃ§ermelidir
            - KarmaÅŸÄ±k && zincirleri KURMA 
            - Her komutu AYRI BÄ°R ADIM olarak yaz
            - Plan, doÄŸrudan bir betik gibi Ã§alÄ±ÅŸtÄ±rÄ±labilir olmalÄ±

            KullanÄ±labilir araÃ§lar:
            - find_and_prepare_gpu: Yeni pod oluÅŸturmak iÃ§in
            - execute_ssh_command: Tek bash komutu Ã§alÄ±ÅŸtÄ±rmak iÃ§in
            - get_pod_status: Pod durumunu kontrol etmek iÃ§in

            Format:
            1. [execute_ssh_command] pwd
            2. [execute_ssh_command] ls -la
            3. [execute_ssh_command] mkdir /workspace/proje
            4. [execute_ssh_command] cd /workspace/proje
            5. [execute_ssh_command] echo "print('hello')" > test.py
            6. [execute_ssh_command] python test.py

            Ã–NEMLÄ°: Her komut ayrÄ± satÄ±r, tek iÅŸlem, bash uyumlu!"""),
            ("user", "GÃ¶rev: {task}")
        ])
        
        try:
            response = self.llm.invoke(planning_prompt.format_messages(task=state["input"]))
            plan_text = response.content
            
            # Plan metnini parse et
            plan_steps = []
            for line in plan_text.split('\n'):
                line = line.strip()
                if line and any(line.startswith(f"{i}.") for i in range(1, 20)):
                    plan_steps.append(line)
            
            print(f"ğŸ“‹ Plan oluÅŸturuldu: {len(plan_steps)} adÄ±m")
            for i, step in enumerate(plan_steps, 1):
                print(f"   {i}. {step}")
            
            return {
                "plan": plan_steps,
                "current_step_index": 0,
                "executed_steps": []
            }
            
        except Exception as e:
            print(f"âŒ Planlama hatasÄ±: {e}")
            return {
                "plan": ["[HATA] Plan oluÅŸturulamadÄ±"],
                "current_step_index": 0,
                "executed_steps": [],
                "final_result": f"Planlama hatasÄ±: {str(e)}"
            }

    # === Ä°Å Ä°STASYONU 3: YENÄ° Ä°CRA DÃœÄÃœMÃœ ===
    def execute_step(self, state: AgentState) -> Dict:
        """
        Plandaki sÄ±radaki bash komutunu analiz eder ve Ã§alÄ±ÅŸtÄ±rÄ±r.
        Her adÄ±m tek bir bash komutu iÃ§erir.
        """
        current_index = state["current_step_index"]
        plan = state["plan"]
        
        if current_index >= len(plan):
            print("âœ… [Ä°CRA DÃœÄÃœMÃœ] TÃ¼m adÄ±mlar tamamlandÄ±!")
            return {"current_step_index": current_index}
        
        current_step = plan[current_index]
        print(f"\nâš¡ [Ä°CRA DÃœÄÃœMÃœ] AdÄ±m {current_index + 1}/{len(plan)}: {current_step}")
        
        try:
            # 1. SÄ±radaki komutu al ve ayrÄ±ÅŸtÄ±r
            tool_name, bash_command = self._parse_bash_command(current_step, state)
            
            # 2. DoÄŸru aracÄ± Ã§aÄŸÄ±r
            if tool_name in self.tools_dict:
                print(f"ğŸ”§ AraÃ§ '{tool_name}' Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
                print(f"ğŸ“‹ Bash komutu: {bash_command}")
                
                # Pod ID'sini Ã¶nceki adÄ±mlardan al
                pod_id = self._extract_pod_id_from_context(state)
                
                # Parametreleri hazÄ±rla
                if tool_name == "execute_ssh_command":
                    tool_params = {"pod_id": pod_id, "command": bash_command}
                elif tool_name == "find_and_prepare_gpu":
                    tool_params = {"min_memory_gb": 16}  # default
                elif tool_name == "get_pod_status":
                    tool_params = {"pod_id": pod_id}
                else:
                    tool_params = {}
                
                # AracÄ± Ã§alÄ±ÅŸtÄ±r
                try:
                    result = self.tools_dict[tool_name].invoke(tool_params)
                except:
                    # Fallback: Direct function call
                    result = self.tools_dict[tool_name](**tool_params)
                
                # 3. Sonucu kaydet
                step_result = {
                    "step_number": current_index + 1,
                    "step_description": current_step,
                    "tool_used": tool_name,
                    "bash_command": bash_command,
                    "result": result,
                    "status": "success" if result.get("status") == "success" else "error"
                }
                
                print(f"âœ… AdÄ±m {current_index + 1} tamamlandÄ±!")
                if result.get("output"):
                    print(f"ğŸ“¤ Ã‡Ä±ktÄ±: {result.get('output', '')[:100]}...")
                
            else:
                step_result = {
                    "step_number": current_index + 1,
                    "step_description": current_step,
                    "tool_used": tool_name,
                    "bash_command": bash_command,
                    "result": f"Bilinmeyen araÃ§: {tool_name}",
                    "status": "error"
                }
                print(f"âŒ Bilinmeyen araÃ§: {tool_name}")
            
            # 4. Bir sonraki adÄ±ma geÃ§
            return {
                "executed_steps": [step_result],
                "current_step_index": current_index + 1
            }
            
        except Exception as e:
            print(f"âŒ AdÄ±m {current_index + 1} hatasÄ±: {e}")
            error_result = {
                "step_number": current_index + 1,
                "step_description": current_step,
                "result": f"Hata: {str(e)}",
                "status": "error"
            }
            
            return {
                "executed_steps": [error_result],
                "current_step_index": current_index + 1
            }

    def _parse_bash_command(self, step: str, state: AgentState) -> tuple:
        """
        AdÄ±m metninden araÃ§ adÄ±nÄ± ve bash komutunu Ã§Ä±karÄ±r.
        Format: "[tool_name] bash_command"
        """
        # [ARAÃ‡_ADI] formatÄ±nÄ± ara
        if '[' in step and ']' in step:
            start = step.index('[') + 1
            end = step.index(']')
            tool_name = step[start:end]
            bash_command = step[end+1:].strip()
        else:
            # Fallback
            tool_name = "execute_ssh_command"
            bash_command = step.strip()
        
        return tool_name, bash_command

    def _extract_pod_id_from_context(self, state: AgentState) -> str:
        """
        User input'tan veya Ã¶nceki adÄ±mlardan pod ID'sini Ã§Ä±karÄ±r.
        """
        # Ã–nce user input'tan ara
        user_input = state.get("input", "")
        import re
        match = re.search(r'\b[a-z0-9]{14}\b', user_input)
        if match:
            return match.group()
        
        # Sonra executed_steps'ten ara
        for step in state.get("executed_steps", []):
            if step.get("tool_used") == "find_and_prepare_gpu":
                result = step.get("result", {})
                if isinstance(result, dict):
                    if "pod_id" in result:
                        return result["pod_id"]
                    if "pod_info" in result:
                        return result["pod_info"].get("id", "")
        
        return "unknown_pod"

    def _extract_pod_id_from_history(self, executed_steps: List[Dict]) -> str:
        """
        Ã–nceki adÄ±mlardan Pod ID'sini bulur.
        """
        for step in executed_steps:
            if step.get("tool_used") == "find_and_prepare_gpu":
                result = step.get("result", {})
                if isinstance(result, dict):
                    # Ã–nce direkt pod_id'yi kontrol et
                    if "pod_id" in result:
                        return result["pod_id"]
                    # Sonra pod_info iÃ§inde ara
                    if "pod_info" in result:
                        return result["pod_info"].get("id", "")
        return ""

    # === Ä°Å Ä°STASYONU 3: RAPORLAMA DÃœÄÃœMÃœ ===
    def generate_response(self, state: AgentState) -> Dict:
        """
        TÃ¼m adÄ±mlarÄ±n sonuÃ§larÄ±nÄ± Ã¶zetleyerek nihai cevap oluÅŸturur.
        """
        print("\nğŸ“Š [RAPORLAMA DÃœÄÃœMÃœ] Nihai rapor hazÄ±rlanÄ±yor...")
        
        executed_steps = state["executed_steps"]
        original_task = state["input"]
        
        # Ã–zet oluÅŸtur
        summary_parts = [f"**GÃ¶rev:** {original_task}\n"]
        
        success_count = 0
        error_count = 0
        
        for step in executed_steps:
            step_num = step.get("step_number", "?")
            status = step.get("status", "unknown")
            description = step.get("step_description", "")
            
            if status == "success":
                success_count += 1
                summary_parts.append(f"âœ… **AdÄ±m {step_num}:** {description}")
            else:
                error_count += 1
                summary_parts.append(f"âŒ **AdÄ±m {step_num}:** {description}")
        
        # Genel durum
        if error_count == 0:
            final_status = f"ğŸ‰ **BAÅARILI!** TÃ¼m {success_count} adÄ±m baÅŸarÄ±yla tamamlandÄ±."
        else:
            final_status = f"âš ï¸ **KISMÄ° BAÅARILI:** {success_count} adÄ±m baÅŸarÄ±lÄ±, {error_count} adÄ±m hatalÄ±."
        
        summary_parts.insert(1, final_status + "\n")
        
        final_result = "\n".join(summary_parts)
        
        print("ğŸ“‹ Nihai rapor oluÅŸturuldu!")
        return {"final_result": final_result}

    # === KARAR VERÄ°CÄ° ===
    def should_continue_execution(self, state: AgentState) -> str:
        """
        Planda daha adÄ±m var mÄ± kontrol eder.
        """
        current_index = state["current_step_index"]
        total_steps = len(state["plan"])
        
        if current_index < total_steps:
            print(f"ğŸ”„ [KARAR] Devam: {current_index}/{total_steps} adÄ±m tamamlandÄ±")
            return "continue"
        else:
            print(f"ğŸ [KARAR] BitiÅŸ: TÃ¼m {total_steps} adÄ±m tamamlandÄ±")
            return "generate_response"

    # === YENÄ° ÅEHIR HARÄ°TASI (AkÄ±llÄ± YÃ¶nlendirmeli Graf OluÅŸturucu) ===
    def build_graph(self):
        """
        AkÄ±llÄ± yÃ¶nlendirme sistemi ile Ã§ok adÄ±mlÄ± iÅŸ akÄ±ÅŸÄ±nÄ±n grafiÄŸini oluÅŸturur.
        """
        print("ğŸ—ºï¸ GraphAgent haritasÄ± Ã§iziliyor...")
        
        workflow = StateGraph(AgentState)
        
        # YENÄ° Ä°Å Ä°STASYONLARI: AkÄ±llÄ± yÃ¶nlendirme sistemi
        workflow.add_node("route_query", self.route_query)      # GÃ¼venlik gÃ¶revlisi
        workflow.add_node("chatbot_step", self.chatbot_step)    # Sohbet masasÄ±
        
        # ESKÄ° Ä°Å Ä°STASYONLARI: KarmaÅŸÄ±k gÃ¶rev iÅŸleme sistemi  
        workflow.add_node("plan_step", self.plan_step)
        workflow.add_node("execute_step", self.execute_step) 
        workflow.add_node("generate_response", self.generate_response)
        
        # YENÄ° BAÅLANGIÃ‡ NOKTASI: ArtÄ±k gÃ¼venlik gÃ¶revlisi kapÄ±da!
        workflow.set_entry_point("route_query")
        
        # YENÄ° AKILLI YOLLAR: KoÅŸullu yÃ¶nlendirme sistemi
        workflow.add_conditional_edges(
            "route_query",
            lambda state: state["route_decision"],
            {
                "chat": "chatbot_step",        # Basit sohbet â†’ Sohbet masasÄ±
                "task": "plan_step"           # KarmaÅŸÄ±k gÃ¶rev â†’ Planlama bÃ¶lÃ¼mÃ¼  
            }
        )
        
        # SOHBET YOLU: Direkt bitiÅŸe gidiyor (hiÃ§ araÃ§ kullanmÄ±yor)
        workflow.add_edge("chatbot_step", END)
        
        # GÃ–REV YOLU: Eskiden olduÄŸu gibi karmaÅŸÄ±k sÃ¼reÃ§
        workflow.add_edge("plan_step", "execute_step")
        
        workflow.add_conditional_edges(
            "execute_step",
            self.should_continue_execution,
            {
                "continue": "execute_step",              # DÃ¶ngÃ¼: Bir sonraki adÄ±ma
                "generate_response": "generate_response" # Bitirme: Raporlama
            }
        )
        
        workflow.add_edge("generate_response", END)
        
        print("âœ… Graf baÅŸarÄ±yla oluÅŸturuldu!")
        return workflow.compile()

    def run(self, query: str) -> Dict:
        """
        AkÄ±llÄ± yÃ¶nlendirmeli gÃ¶rev yÃ¼rÃ¼tÃ¼cÃ¼sÃ¼.
        """
        print(f"\nğŸš€ [GÃ–REV BAÅLADI] {query}")
        
        initial_state = {
            "input": query,
            "route_decision": "",     # YENÄ°: YÃ¶nlendirme kararÄ±
            "plan": [],
            "executed_steps": [], 
            "current_step_index": 0,
            "final_result": ""
        }
        
        final_state = self.graph.invoke(initial_state, {"recursion_limit": 50})
        
        print("\nğŸ¯ [GÃ–REV TAMAMLANDI]")
        return {
            "result": final_state.get("final_result", "SonuÃ§ oluÅŸturulamadÄ±"),
            "intermediate_steps": final_state.get("executed_steps", []),
            "plan": final_state.get("plan", [])
        }


# === FACTORY FUNCTION ===
def create_graph_agent():
    """GraphAgent instance oluÅŸturur."""
    return GraphAgent()


# --- Test BloÄŸu ---
if __name__ == '__main__':
    print("ğŸ§ª === Ã‡OK ADIMLI GRAPH AGENT TESLÄ°MÄ° ===")
    
    graph_agent = GraphAgent()
    
    # KarmaÅŸÄ±k test gÃ¶revi
    test_query = (
        "Bana 16GB VRAM'li bir GPU ortamÄ± hazÄ±rla, "
        "ardÄ±ndan PyTorch repository'sini clone et ve kurulumunu yap."
    )
    
    print(f"\nğŸ“ Test GÃ¶revi: {test_query}")
    result_state = graph_agent.run(test_query)
    
    print("\n" + "="*80)
    print("ğŸ¯ SONUÃ‡:")
    print(result_state.get("result", "SonuÃ§ bulunamadÄ±"))
    print("="*80)
    
    # Plan ve adÄ±mlarÄ± da gÃ¶ster
    if "plan" in result_state:
        print(f"\nğŸ“‹ OluÅŸturulan Plan ({len(result_state['plan'])} adÄ±m):")
        for i, step in enumerate(result_state["plan"], 1):
            print(f"  {i}. {step}")
    
    if "intermediate_steps" in result_state:
        print(f"\nâš¡ GerÃ§ekleÅŸtirilen AdÄ±mlar ({len(result_state['intermediate_steps'])}):")
        for step in result_state["intermediate_steps"]:
            status = "âœ…" if step.get("status") == "success" else "âŒ"
            print(f"  {status} AdÄ±m {step.get('step_number', '?')}: {step.get('step_description', 'N/A')}")

