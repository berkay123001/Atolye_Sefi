# tools/operational_tools.py

import sys
import os
import requests
import time
import json
import re
from typing import Dict, List, Any
from pydantic.v1 import BaseModel, Field

# LangChain araÃ§larÄ± iÃ§in gerekli importlar
from langchain.tools import tool

try:
    from config import settings
except ImportError:
    print("Hata: config.py bulunamadÄ±.")
    sys.exit(1)

# --- YardÄ±mcÄ± Fonksiyonlar ---
def _run_graphql_query(query: str, variables: Dict = None) -> Dict:
    """GraphQL sorgusu Ã§alÄ±ÅŸtÄ±rmak iÃ§in yardÄ±mcÄ± fonksiyon."""
    api_url = "https://api.runpod.io/graphql"
    headers = {"Authorization": f"Bearer {settings.RUNPOD_API_KEY}", "Content-Type": "application/json"}
    try:
        response = requests.post(api_url, headers=headers, json={'query': query, 'variables': variables or {}})
        if response.status_code != 200:
            error_details = response.json() if response.headers.get('Content-Type') == 'application/json' else response.text
            return {"errors": [{"message": f"API'den {response.status_code} hatasÄ± alÄ±ndÄ±.", "details": error_details}]}
        return response.json()
    except requests.exceptions.RequestException as e:
        return {"errors": [{"message": str(e)}]}

def _start_pod(pod_id: str) -> Dict:
    """Belirtilen ID'ye sahip bir pod'u baÅŸlatÄ±r."""
    print(f"[Pod Start] Pod '{pod_id}' baÅŸlatÄ±lÄ±yor...")
    mutation = """
    mutation podResume($input: PodResumeInput!) {
        podResume(input: $input) {
            id
            desiredStatus
            lastStatusChange
        }
    }
    """
    variables = {"input": {"podId": pod_id, "gpuCount": 1}}
    result = _run_graphql_query(mutation, variables)
    if "errors" in result or not result.get("data", {}).get("podResume"):
        error_message = result.get("errors", [{}])[0].get("message", "Bilinmeyen bir hata oluÅŸtu.")
        print(f"âŒ Pod baÅŸlatÄ±lamadÄ±: {error_message}")
        return {"status": "error", "message": f"Pod '{pod_id}' baÅŸlatÄ±lamadÄ±.", "details": error_message}
    
    print(f"[Pod Start] Pod '{pod_id}' baÅŸlatma komutu gÃ¶nderildi")
    return {"status": "success", "message": f"Pod '{pod_id}' baÅŸarÄ±yla baÅŸlatÄ±ldÄ±", "pod_id": pod_id, **result["data"]["podResume"]}

def _get_web_terminal_info(pod_id: str) -> Dict:
    """Pod'un Web Terminal bilgilerini alÄ±r."""
    query = """
    query pods {
        myself {
            pods {
                id
                name
                machine {
                    podHostId
                }
                runtime {
                    uptimeInSeconds
                    ports {
                        ip
                        isIpPublic
                        privatePort
                        publicPort
                        type
                    }
                }
            }
        }
    }
    """
    
    result = _run_graphql_query(query, {})
    pods = result.get("data", {}).get("myself", {}).get("pods", [])
    
    for pod in pods:
        if pod.get("id") == pod_id:
            runtime = pod.get("runtime", {})
            if runtime:
                ports = runtime.get("ports", [])
                
                # Jupyter Notebook URL (8888 portu)
                jupyter_url = f"https://{pod_id}-8888.proxy.runpod.net/lab/"
                
                # Web Terminal iÃ§in SSH port bulma (genellikle 22)
                ssh_port = None
                for port in ports:
                    if port.get("privatePort") == 22:
                        ssh_port = port.get("publicPort")
                        break
                
                return {
                    "jupyter_url": jupyter_url,
                    "ssh_port": ssh_port,
                    "uptime": runtime.get("uptimeInSeconds", 0),
                    "total_ports": len(ports),
                    "pod_name": pod.get("name", ""),
                    "machine_host": pod.get("machine", {}).get("podHostId", "")
                }
    
    return None

def _get_available_gpus_internal() -> List[Dict]:
    """Mevcut GPU tiplerini listeler (eski uyumluluk iÃ§in)."""
    graphql_query = "query GpuTypes { gpuTypes { id displayName memoryInGb } }"
    data = _run_graphql_query(graphql_query)
    if "errors" in data and data.get("errors"): 
        return []
    return data.get("data", {}).get("gpuTypes", [])

def _prepare_environment_internal(gpu_type_id: str) -> Dict:
    unique_pod_name = f"AtolyeSefi-Pod-{gpu_type_id.replace(' ', '-').lower()}-{int(time.time())}"
    graphql_mutation = f'''
    mutation podFindAndDeployOnDemand {{
      podFindAndDeployOnDemand(
        input: {{
          cloudType: COMMUNITY,
          gpuTypeId: "{gpu_type_id}",
          name: "{unique_pod_name}",
          imageName: "runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04",
          gpuCount: 1,
          volumeInGb: 40,
          volumeMountPath: "/workspace",
          containerDiskInGb: 5
        }}
      ) {{ id, imageName, machineId }}
    }}
    '''
    return _run_graphql_query(graphql_mutation)

# --- "Usta" AraÃ§ ---

@tool
def find_and_prepare_gpu(min_memory_gb: Any = 16) -> Dict:
    """
    Belirtilen minimum VRAM'e sahip GPU'yu bulur ve GERÃ‡EK Pod oluÅŸturur.
    BasitleÅŸtirilmiÅŸ, over-engineering olmayan versiyon.
    """
    # 1. ADIM: Girdileri temizle
    parsed_min_memory_gb = 16
    if isinstance(min_memory_gb, str):
        match = re.search(r'\d+', min_memory_gb)
        if match:
            parsed_min_memory_gb = int(match.group(0))
    elif isinstance(min_memory_gb, int):
        parsed_min_memory_gb = min_memory_gb

    print(f"\n[Pod Creator] GPU aranÄ±yor (Min VRAM: {parsed_min_memory_gb}GB)...")
    
    # 2. ADIM: GPU listesi al
    all_gpus = _get_available_gpus_internal()
    if not all_gpus:
        return {"status": "error", "message": "GPU listesi alÄ±namadÄ±."}

    # API'den gelen veriyi temizle
    def to_int_safe(value: Any) -> int:
        try:
            return int(value)
        except (ValueError, TypeError):
            return 0

    suitable_gpus = [
        gpu for gpu in all_gpus 
        if to_int_safe(gpu.get('memoryInGb')) >= parsed_min_memory_gb
    ]
    
    if not suitable_gpus:
        return {"status": "error", "message": "Uygun GPU bulunamadÄ±."}

    # 3. ADIM: En uygun GPU'yu seÃ§ ve pod oluÅŸtur
    priority_order = ["A4000", "A5000", "RTX 3090", "RTX 4090", "A100"]
    sorted_gpus = sorted(
        suitable_gpus,
        key=lambda gpu: next((priority_order.index(p) for p in priority_order if p in gpu['id']), len(priority_order))
    )
    
    for gpu in sorted_gpus:
        gpu_id = gpu['id']
        print(f"[Pod Creator] '{gpu_id}' deneniyor...")
        result = _prepare_environment_internal(gpu_id)
        
        if "errors" in result and result.get("errors"):
            error_message = result['errors'][0].get('message', '')
            if "instances available" in error_message:
                print(f"[Pod Creator] '{gpu_id}' mevcut deÄŸil. Sonraki deneniyor...")
                continue
            else:
                return {"status": "error", "message": f"'{gpu_id}' iÃ§in API hatasÄ±.", "details": error_message}
        
        pod_data = result.get("data", {}).get("podFindAndDeployOnDemand")
        if pod_data:
            print(f"[Pod Creator] BAÅARILI! '{gpu_id}' ile Pod oluÅŸturuldu.")
            
            # 4. ADIM: Pod'un hazÄ±r olmasÄ±nÄ± bekle ve gerÃ§ek URL'i al
            pod_id = pod_data.get("id")
            print(f"[Pod Creator] Pod ID: {pod_id}")
            print(f"[Pod Creator] Pod'un hazÄ±r olmasÄ± bekleniyor...")
            
            # Pod'un ports bilgisini almak iÃ§in bekleme dÃ¶ngÃ¼sÃ¼
            jupyter_url = None
            max_attempts = 15
            for attempt in range(max_attempts):
                print(f"   - Pod hazÄ±rlÄ±k kontrol denemesi [{attempt + 1}/{max_attempts}]...")
                
                # Pod durumunu kontrol et
                status_query = """
                query pods {
                    myself {
                        pods {
                            id
                            runtime {
                                uptimeInSeconds
                                ports {
                                    ip
                                    isIpPublic
                                    privatePort
                                    publicPort
                                    type
                                }
                            }
                        }
                    }
                }
                """
                status_result = _run_graphql_query(status_query)
                
                # Bizim pod'umuzu bul
                pods = status_result.get("data", {}).get("myself", {}).get("pods", [])
                current_pod = None
                for pod in pods:
                    if pod.get("id") == pod_id:
                        current_pod = pod
                        break
                
                if current_pod and current_pod.get("runtime"):
                    runtime = current_pod.get("runtime", {})
                    uptime = runtime.get("uptimeInSeconds", 0)
                    ports = runtime.get("ports", [])
                    
                    print(f"   ğŸ“Š Pod durumu: {len(ports)} port mevcut, Ã§alÄ±ÅŸma sÃ¼resi: {uptime}s")
                    
                    # Port 8888'i arÄ±yoruz (Jupyter Notebook)
                    for port in ports:
                        if port.get("privatePort") == 8888:
                            jupyter_url = f"https://{pod_id}-8888.proxy.runpod.net/lab/"
                            print(f"   âœ… Jupyter Notebook hazÄ±r: {jupyter_url}")
                            break
                    
                    if jupyter_url:
                        break
                else:
                    print(f"   - Pod runtime henÃ¼z hazÄ±r deÄŸil, bekleniyor...")
                
                if attempt < max_attempts - 1:
                    time.sleep(10)
            
            if not jupyter_url:
                jupyter_url = f"https://{pod_id}-8888.proxy.runpod.net/lab/"
                print(f"   âš ï¸ Zaman aÅŸÄ±mÄ± - varsayÄ±lan URL kullanÄ±lÄ±yor: {jupyter_url}")
            
            print(f"[Pod Creator] Final Jupyter URL: {jupyter_url}")
            
            return {
                "status": "success", 
                "message": f"'{gpu_id}' ile Pod baÅŸarÄ±yla oluÅŸturuldu.", 
                "pod_info": pod_data,
                "pod_id": pod_id,
                "jupyter_url": jupyter_url
            }

    return {"status": "error", "message": "HiÃ§bir GPU ÅŸu anda mevcut deÄŸil."}

# --- Pod Komut Ã‡alÄ±ÅŸtÄ±rma AracÄ± ---

class StartTaskInput(BaseModel):
    pod_id: str = Field(description="Komutun Ã§alÄ±ÅŸtÄ±rÄ±lacaÄŸÄ± Pod'un ID'si")
    command: str = Field(description="Pod'da Ã§alÄ±ÅŸtÄ±rÄ±lacak terminal komutu")

@tool(args_schema=StartTaskInput)
def start_task_on_pod(pod_id: str, command: str) -> Dict[str, Any]:
    """
    Pod'da komut Ã§alÄ±ÅŸtÄ±rma simÃ¼lasyonu yapar ve Jupyter URL'ini saÄŸlar.
    RunPod'un GraphQL API'si direkt komut Ã§alÄ±ÅŸtÄ±rmayÄ± desteklemediÄŸi iÃ§in,
    kullanÄ±cÄ±nÄ±n manuel olarak Jupyter Notebook'a gidip kodu Ã§alÄ±ÅŸtÄ±rmasÄ± Ã¶nerilir.
    """
    print(f"\n[Command Executor] Pod '{pod_id}' iÃ§in komut hazÄ±rlanÄ±yor...")
    print(f"[Command Executor] Komut: {command}")
    
    # Jupyter URL'ini oluÅŸtur
    jupyter_url = f"https://{pod_id}-8888.proxy.runpod.net/lab/"
    
    # Komutu Jupyter Notebook iÃ§in uygun hale getir
    if command.startswith("echo"):
        # Echo komutlarÄ±nÄ± Python print'e Ã§evir
        if ">" in command:
            # Dosya yazma operasyonu
            parts = command.split(" > ")
            content = parts[0].replace("echo", "").strip().strip('"').strip("'")
            filename = parts[1].strip()
            jupyter_code = f'''# Dosya oluÅŸturma
with open("{filename}", "w") as f:
    f.write("{content}")
print("Dosya '{filename}' oluÅŸturuldu!")'''
        else:
            # Basit echo
            content = command.replace("echo", "").strip().strip('"').strip("'")
            jupyter_code = f'print("{content}")'
    elif command.startswith("git clone"):
        # Git clone komutunu Ã§evir
        jupyter_code = f'''# Git repository klonlama
import subprocess
result = subprocess.run("{command}", shell=True, capture_output=True, text=True)
print("STDOUT:", result.stdout)
print("STDERR:", result.stderr)
print("Return code:", result.returncode)'''
    elif command.startswith("pip install"):
        # Pip install komutunu Ã§evir
        packages = command.replace("pip install", "").strip()
        jupyter_code = f'''# Paket kurulumu
import subprocess
result = subprocess.run("pip install {packages}", shell=True, capture_output=True, text=True)
print("STDOUT:", result.stdout)
print("STDERR:", result.stderr)
print("Return code:", result.returncode)'''
    else:
        # DiÄŸer komutlar iÃ§in genel shell execution
        jupyter_code = f'''# Komut Ã§alÄ±ÅŸtÄ±rma
import subprocess
result = subprocess.run("{command}", shell=True, capture_output=True, text=True)
print("STDOUT:", result.stdout)
print("STDERR:", result.stderr)
print("Return code:", result.returncode)'''
    
    print(f"[Command Executor] âœ… Jupyter kodu hazÄ±rlandÄ±!")
    print(f"[Command Executor] Jupyter URL: {jupyter_url}")
    
    return {
        "status": "success",
        "message": "Komut Jupyter Notebook iÃ§in hazÄ±rlandÄ±.",
        "jupyter_url": jupyter_url,
        "jupyter_password": "atolye123",
        "original_command": command,
        "jupyter_code": jupyter_code,
        "instructions": f"""Pod'da kodu Ã§alÄ±ÅŸtÄ±rmak iÃ§in:
1. Jupyter URL'ini aÃ§: {jupyter_url}
2. Åifre gir: atolye123
3. Yeni notebook oluÅŸtur veya terminal aÃ§
4. AÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±r:

{jupyter_code}""",
        "pod_id": pod_id
    }

# --- Test BloÄŸu: GerÃ§ek Pod ile Komut Ã‡alÄ±ÅŸtÄ±rma ---
if __name__ == '__main__':
    print("ğŸ§ª === FAZ 2 FÄ°NAL TESLÄ°MÄ°: GERÃ‡EK POD KOMUT Ã‡ALIÅTIRMA ===")
    print("Bu test, gerÃ§ek bir Pod oluÅŸturacak ve iÃ§inde komut Ã§alÄ±ÅŸtÄ±racak!\n")
    
    # 1. ADIM: GerÃ§ek Pod oluÅŸtur
    print("1ï¸âƒ£ ADIM: GPU Pod oluÅŸturuluyor...")
    pod_result = find_and_prepare_gpu.invoke({"min_memory_gb": 16})
    
    if pod_result.get("status") != "success":
        print(f"âŒ Pod oluÅŸturulamadÄ±: {pod_result}")
        exit(1)
    
    pod_id = pod_result.get("pod_id")
    if not pod_id:
        # Fallback: pod_info'dan almaya Ã§alÄ±ÅŸ
        pod_info = pod_result.get("pod_info", {})
        pod_id = pod_info.get("id")
    
    if not pod_id:
        print("âŒ Pod ID alÄ±namadÄ±!")
        exit(1)
        
    print(f"âœ… Pod baÅŸarÄ±yla oluÅŸturuldu! ID: {pod_id}")
    print(f"ğŸ”— Jupyter URL: {pod_result.get('jupyter_url', 'N/A')}")
    
    # 2. ADIM: Pod'un tamamen hazÄ±r olmasÄ±nÄ± bekle
    print(f"\n2ï¸âƒ£ ADIM: Pod'un RUNNING durumuna geÃ§mesi bekleniyor...")
    print("â³ 60 saniye sabÄ±rlÄ± bekleme (Pod baÅŸlatma sÃ¼reci)...")
    time.sleep(60)
    
    # 3. ADIM: GerÃ§ek komut Ã§alÄ±ÅŸtÄ±r
    print(f"\n3ï¸âƒ£ ADIM: Pod'da test komutu Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
    test_command = "echo 'Merhaba Atolye Sefi!' > /workspace/test.txt && ls -l /workspace && cat /workspace/test.txt"
    
    command_result = start_task_on_pod.invoke({
        "pod_id": pod_id,
        "command": test_command
    })
    
    print("\n" + "="*80)
    print("ğŸ¯ SONUÃ‡LAR:")
    print("="*80)
    print(f"Pod OluÅŸturma: {pod_result.get('status')}")
    print(f"Komut Ã‡alÄ±ÅŸtÄ±rma: {command_result.get('status')}")
    
    if command_result.get("status") == "success":
        print(f"âœ… Job ID: {command_result.get('job_id')}")
        print(f"âœ… Status: {command_result.get('initial_status')}")
        print(f"âœ… Command: {command_result.get('command')}")
        print("\nğŸ‰ FAZ 2 TAMAMLANDI! Ajan artÄ±k gerÃ§ek Pod'larda komut Ã§alÄ±ÅŸtÄ±rabiliyor!")
    else:
        print(f"âŒ Komut Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {command_result.get('message')}")
    
    print("\nğŸ’¡ Jupyter Notebook'u manuel kontrol iÃ§in:")
    print(f"   URL: {pod_result.get('jupyter_url', 'N/A')}")
    print("   Password: atolye123")
    print("="*80)
