#!/usr/bin/env python3
"""
üß™ ADVANCED TEST CATEGORIES SYSTEM
Claude Code entegrasyonu ile geli≈ümi≈ü test kategorileri ve otomatik hata d√ºzeltme sistemi
"""

import json
import time
import os
import sys
import traceback
import subprocess
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import requests
import google.generativeai as genai

# Import the terminal agent
try:
    from tools.terminal_agent import TerminalAgent, AdvancedIntentClassifier
    from tools.automated_test_suite import TestResult, TerminalAgentTestSuite
except ImportError:
    try:
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from terminal_agent import TerminalAgent, AdvancedIntentClassifier
        from automated_test_suite import TestResult, TerminalAgentTestSuite
    except ImportError:
        print("‚ùå Error: Could not import required modules. Make sure all files are available.")
        sys.exit(1)

@dataclass
class IssueReport:
    """Detaylƒ± issue raporu yapƒ±sƒ±"""
    issue_id: str
    category: str
    severity: str  # CRITICAL, HIGH, MEDIUM, LOW
    title: str
    description: str
    test_input: str
    expected_behavior: str
    actual_behavior: str
    error_trace: Optional[str]
    suggested_fixes: List[str]
    claude_analysis: Optional[str]
    timestamp: str
    status: str  # OPEN, IN_PROGRESS, RESOLVED, CLOSED

@dataclass
class TestCategory:
    """Test kategorisi yapƒ±sƒ±"""
    name: str
    description: str
    test_cases: List[Dict]
    priority: str
    gemini_enhanced: bool = False

class AdvancedTestCategoriesSystem:
    """Geli≈ümi≈ü test kategorileri sistemi - Claude Code entegrasyonu ile"""
    
    def __init__(self):
        """Initialize advanced test system"""
        self.agent = TerminalAgent()
        self.base_test_suite = TerminalAgentTestSuite()
        self.test_results: List[TestResult] = []
        self.issue_reports: List[IssueReport] = []
        self.start_time = None
        self.end_time = None
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        
        # Gemini setup
        if self.gemini_api_key:
            genai.configure(api_key=self.gemini_api_key)
            self.gemini_model = genai.GenerativeModel('gemini-pro')
        else:
            print("‚ö†Ô∏è GEMINI_API_KEY not found. Gemini features will be disabled.")
            self.gemini_model = None
        
        # üéØ GELƒ∞≈ûMƒ∞≈û TEST KATEGORƒ∞LERƒ∞
        self.advanced_categories = {
            "claude_code_integration": TestCategory(
                name="Claude Code Integration Tests",
                description="Claude Code ile entegrasyon testleri",
                priority="CRITICAL",
                gemini_enhanced=True,
                test_cases=[
                    {
                        "input": "claude code ile dosya analizi yap",
                        "expected_claude_integration": True,
                        "should_suggest_claude_commands": True,
                        "description": "Claude Code dosya analizi entegrasyonu"
                    },
                    {
                        "input": "hatalarƒ± claude ile d√ºzelt",
                        "expected_claude_integration": True,
                        "should_provide_fix_commands": True,
                        "description": "Claude Code hata d√ºzeltme entegrasyonu"
                    },
                    {
                        "input": "test sonu√ßlarƒ±nƒ± claude'a g√∂nder",
                        "expected_export_format": "claude_compatible",
                        "should_create_analysis_prompts": True,
                        "description": "Claude Code test sonucu aktarƒ±mƒ±"
                    }
                ]
            ),
            
            "gemini_enhanced_testing": TestCategory(
                name="Gemini Enhanced Testing",
                description="Gemini AI ile geli≈ütirilmi≈ü test senaryolarƒ±",
                priority="HIGH",
                gemini_enhanced=True,
                test_cases=[
                    {
                        "input": "gemini ile test senaryosu olu≈ütur",
                        "expected_gemini_usage": True,
                        "test_scenario_quality": "professional",
                        "description": "Gemini test senaryosu olu≈üturma"
                    },
                    {
                        "input": "karma≈üƒ±k python problemi √ß√∂z",
                        "expected_complexity_handling": "advanced",
                        "should_use_gemini_reasoning": True,
                        "description": "Gemini karma≈üƒ±k problem √ß√∂zme"
                    },
                    {
                        "input": "kod kalitesi analizi yap",
                        "expected_analysis_depth": "comprehensive",
                        "should_provide_recommendations": True,
                        "description": "Gemini kod kalitesi analizi"
                    }
                ]
            ),
            
            "error_recovery_system": TestCategory(
                name="Error Recovery System Tests",
                description="Hata kurtarma ve otomatik d√ºzeltme testleri",
                priority="HIGH",
                gemini_enhanced=False,
                test_cases=[
                    {
                        "input": "bozuk kod dosyasƒ± d√ºzelt",
                        "should_detect_syntax_errors": True,
                        "should_suggest_fixes": True,
                        "expected_recovery_success": True,
                        "description": "Syntax hatasƒ± kurtarma"
                    },
                    {
                        "input": "eksik import'larƒ± bul ve ekle",
                        "should_detect_missing_imports": True,
                        "should_auto_add_imports": True,
                        "description": "Eksik import kurtarma"
                    },
                    {
                        "input": "runtime hatasƒ± √ß√∂z",
                        "should_analyze_runtime_error": True,
                        "should_provide_solution": True,
                        "description": "Runtime hata kurtarma"
                    }
                ]
            ),
            
            "performance_optimization": TestCategory(
                name="Performance Optimization Tests",
                description="Performans optimizasyonu testleri",
                priority="MEDIUM",
                gemini_enhanced=True,
                test_cases=[
                    {
                        "input": "kodu optimize et",
                        "expected_optimization_suggestions": True,
                        "should_measure_improvement": True,
                        "description": "Kod optimizasyonu"
                    },
                    {
                        "input": "bellek kullanƒ±mƒ±nƒ± azalt",
                        "should_analyze_memory_usage": True,
                        "should_suggest_memory_optimizations": True,
                        "description": "Bellek optimizasyonu"
                    },
                    {
                        "input": "hƒ±z iyile≈ütirmesi yap",
                        "should_profile_performance": True,
                        "should_suggest_speed_improvements": True,
                        "description": "Hƒ±z optimizasyonu"
                    }
                ]
            ),
            
            "security_analysis": TestCategory(
                name="Security Analysis Tests",
                description="G√ºvenlik analizi testleri",
                priority="HIGH",
                gemini_enhanced=True,
                test_cases=[
                    {
                        "input": "g√ºvenlik a√ßƒ±ƒüƒ± tara",
                        "should_detect_vulnerabilities": True,
                        "should_suggest_security_fixes": True,
                        "description": "G√ºvenlik a√ßƒ±ƒüƒ± tarama"
                    },
                    {
                        "input": "kod g√ºvenliƒüi analizi",
                        "expected_security_report": True,
                        "should_rate_security_level": True,
                        "description": "Kod g√ºvenliƒüi analizi"
                    },
                    {
                        "input": "g√ºvenli kod yazmak i√ßin √∂neriler",
                        "should_provide_security_guidelines": True,
                        "should_give_best_practices": True,
                        "description": "G√ºvenlik √∂nerileri"
                    }
                ]
            ),
            
            "ml_workflow_testing": TestCategory(
                name="ML Workflow Testing",
                description="Machine Learning i≈ü akƒ±≈üƒ± testleri",
                priority="MEDIUM",
                gemini_enhanced=True,
                test_cases=[
                    {
                        "input": "makine √∂ƒürenmesi modeli olu≈ütur",
                        "should_create_ml_pipeline": True,
                        "expected_model_quality": "production_ready",
                        "description": "ML model olu≈üturma"
                    },
                    {
                        "input": "veri analizi raporu hazƒ±rla",
                        "should_analyze_data": True,
                        "should_create_visualizations": True,
                        "description": "Veri analizi raporu"
                    },
                    {
                        "input": "model performansƒ±nƒ± deƒüerlendir",
                        "should_calculate_metrics": True,
                        "should_suggest_improvements": True,
                        "description": "Model performans deƒüerlendirme"
                    }
                ]
            ),
            
            "collaborative_development": TestCategory(
                name="Collaborative Development Tests",
                description="ƒ∞≈übirlikli geli≈ütirme testleri",
                priority="MEDIUM",
                gemini_enhanced=False,
                test_cases=[
                    {
                        "input": "kod review yap",
                        "should_analyze_code_quality": True,
                        "should_suggest_improvements": True,
                        "description": "Kod review"
                    },
                    {
                        "input": "git commit mesajƒ± olu≈ütur",
                        "should_generate_commit_message": True,
                        "expected_message_quality": "professional",
                        "description": "Git commit mesajƒ± olu≈üturma"
                    },
                    {
                        "input": "dok√ºmantasyon yaz",
                        "should_create_documentation": True,
                        "expected_documentation_completeness": "comprehensive",
                        "description": "Dok√ºmantasyon olu≈üturma"
                    }
                ]
            )
        }
    
    def generate_gemini_test_scenarios(self, category: str, complexity_level: str = "advanced") -> List[Dict]:
        """Gemini ile geli≈ümi≈ü test senaryolarƒ± olu≈ütur"""
        if not self.gemini_model:
            print("‚ö†Ô∏è Gemini model not available. Skipping scenario generation.")
            return []
        
        prompt = f"""
        {category} kategorisi i√ßin {complexity_level} seviyesinde test senaryolarƒ± olu≈ütur.
        
        Her test senaryosu ≈üu format'ta olmalƒ±:
        - input: Test girdisi (T√ºrk√ße)
        - expected_behavior: Beklenen davranƒ±≈ü
        - complexity_score: 1-10 arasƒ± karma≈üƒ±klƒ±k skoru
        - success_criteria: Ba≈üarƒ± kriterleri
        - edge_cases: Sƒ±nƒ±r durumlarƒ±
        - description: Test a√ßƒ±klamasƒ±
        
        5 farklƒ± test senaryosu olu≈ütur. JSON formatƒ±nda d√∂nd√ºr.
        """
        
        try:
            response = self.gemini_model.generate_content(prompt)
            # Gemini response'unu parse et
            gemini_scenarios = json.loads(response.text)
            return gemini_scenarios.get('scenarios', [])
        except Exception as e:
            print(f"‚ö†Ô∏è Gemini scenario generation failed: {str(e)}")
            return []
    
    def run_advanced_category_tests(self, category_name: str = None) -> str:
        """Geli≈ümi≈ü kategori testlerini √ßalƒ±≈ütƒ±r"""
        self.start_time = datetime.now()
        print("üß™ ADVANCED TEST CATEGORIES SYSTEM")
        print("=" * 80)
        print(f"üìÖ Test Started: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("üéØ Claude Code Integration + Gemini Enhanced Testing")
        print("=" * 80)
        
        categories_to_test = [category_name] if category_name else list(self.advanced_categories.keys())
        
        for cat_name in categories_to_test:
            if cat_name not in self.advanced_categories:
                print(f"‚ùå Unknown category: {cat_name}")
                continue
                
            category = self.advanced_categories[cat_name]
            print(f"\nüîç Running {category.name} Tests...")
            print(f"üìù Description: {category.description}")
            print(f"‚ö° Priority: {category.priority}")
            
            # Gemini ile geli≈ütirilmi≈ü senaryolar
            if category.gemini_enhanced:
                print("ü§ñ Generating Gemini-enhanced scenarios...")
                gemini_scenarios = self.generate_gemini_test_scenarios(cat_name)
                if gemini_scenarios:
                    category.test_cases.extend(gemini_scenarios)
                    print(f"‚ú® Added {len(gemini_scenarios)} Gemini-generated scenarios")
            
            # Test cases'leri √ßalƒ±≈ütƒ±r
            self.execute_category_tests(category, cat_name)
        
        self.end_time = datetime.now()
        
        # Raporlarƒ± olu≈ütur ve issue'larƒ± kaydet
        self.generate_issue_reports()
        self.export_claude_integration_data()
        
        return self.create_claude_fix_commands()
    
    def execute_category_tests(self, category: TestCategory, category_name: str):
        """Kategori testlerini √ßalƒ±≈ütƒ±r"""
        print(f"\nüìä {category.name} - Executing {len(category.test_cases)} test cases")
        print("-" * 60)
        
        for i, test_case in enumerate(category.test_cases, 1):
            start_time = time.time()
            
            try:
                # Test case'i √ßalƒ±≈ütƒ±r
                response = self.agent.process_request(test_case["input"])
                response_time = time.time() - start_time
                
                # Test sonucunu deƒüerlendir
                success, details = self.evaluate_test_case(test_case, response, category_name)
                
                # Test result olu≈ütur
                test_result = TestResult(
                    test_type=category_name,
                    test_name=test_case.get("description", f"Test {i}"),
                    input_text=test_case["input"],
                    expected=str(test_case.get("expected_behavior", "Success")),
                    actual=response[:200] + "..." if len(response) > 200 else response,
                    success=success,
                    response_time=response_time,
                    details=details
                )
                self.test_results.append(test_result)
                
                # Issue raporu olu≈ütur (ba≈üarƒ±sƒ±z testler i√ßin)
                if not success:
                    self.create_issue_report(test_result, category.priority)
                
                # Konsol √ßƒ±ktƒ±sƒ±
                status = "‚úÖ" if success else "‚ùå"
                print(f"  {status} Test {i:2d}: {test_case['input'][:40]:<40} ‚Üí {response_time:.2f}s")
                
            except Exception as e:
                # Hata durumu
                test_result = TestResult(
                    test_type=category_name,
                    test_name=test_case.get("description", f"Test {i}"),
                    input_text=test_case["input"],
                    expected="Success",
                    actual="ERROR",
                    success=False,
                    response_time=0.0,
                    error=str(e)
                )
                self.test_results.append(test_result)
                self.create_issue_report(test_result, "CRITICAL")
                
                print(f"  ‚ùå Test {i:2d}: {test_case['input'][:40]:<40} ‚Üí ERROR: {str(e)[:30]}")
    
    def evaluate_test_case(self, test_case: Dict, response: str, category: str) -> Tuple[bool, Dict]:
        """Test case'i deƒüerlendir"""
        details = {}
        success_criteria = []
        
        # Kategori-√∂zel deƒüerlendirme
        if category == "claude_code_integration":
            details["claude_integration"] = "claude" in response.lower() or "code" in response.lower()
            success_criteria.append(details["claude_integration"])
            
        elif category == "gemini_enhanced_testing":
            details["gemini_usage"] = len(response) > 100 and any(keyword in response.lower() for keyword in ["analiz", "deƒüerlendirme", "√∂neri"])
            success_criteria.append(details["gemini_usage"])
            
        elif category == "error_recovery_system":
            details["error_detection"] = any(keyword in response.lower() for keyword in ["hata", "error", "d√ºzelt", "fix"])
            success_criteria.append(details["error_detection"])
            
        elif category == "performance_optimization":
            details["optimization_focus"] = any(keyword in response.lower() for keyword in ["optimize", "performans", "hƒ±z", "bellek"])
            success_criteria.append(details["optimization_focus"])
            
        elif category == "security_analysis":
            details["security_focus"] = any(keyword in response.lower() for keyword in ["g√ºvenlik", "security", "a√ßƒ±k", "vulnerability"])
            success_criteria.append(details["security_focus"])
            
        elif category == "ml_workflow_testing":
            details["ml_focus"] = any(keyword in response.lower() for keyword in ["model", "veri", "analiz", "makine √∂ƒürenmesi"])
            success_criteria.append(details["ml_focus"])
            
        elif category == "collaborative_development":
            details["collaboration_focus"] = any(keyword in response.lower() for keyword in ["review", "commit", "dok√ºmantasyon", "git"])
            success_criteria.append(details["collaboration_focus"])
        
        # Genel ba≈üarƒ± kriterleri
        details["response_quality"] = len(response.strip()) > 20
        details["no_errors"] = "error" not in response.lower() and "hata" not in response.lower()
        
        success_criteria.extend([details["response_quality"], details["no_errors"]])
        
        # Genel ba≈üarƒ± durumu
        overall_success = all(success_criteria) if success_criteria else False
        
        return overall_success, details
    
    def create_issue_report(self, test_result: TestResult, severity: str):
        """Ba≈üarƒ±sƒ±z test i√ßin issue raporu olu≈ütur"""
        issue_id = f"ISSUE_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{len(self.issue_reports):03d}"
        
        issue = IssueReport(
            issue_id=issue_id,
            category=test_result.test_type,
            severity=severity,
            title=f"Test Failure: {test_result.test_name}",
            description=f"Test failed for input: '{test_result.input_text}'",
            test_input=test_result.input_text,
            expected_behavior=str(test_result.expected),
            actual_behavior=str(test_result.actual),
            error_trace=test_result.error,
            suggested_fixes=[],
            claude_analysis=None,
            timestamp=datetime.now().isoformat(),
            status="OPEN"
        )
        
        # Claude Analysis isteyeceƒüiz
        issue.suggested_fixes = self.generate_fix_suggestions(test_result)
        
        self.issue_reports.append(issue)
    
    def generate_fix_suggestions(self, test_result: TestResult) -> List[str]:
        """Test sonucuna g√∂re d√ºzeltme √∂nerileri olu≈ütur"""
        suggestions = []
        
        if test_result.test_type == "claude_code_integration":
            suggestions.extend([
                "Claude Code API entegrasyonunu kontrol et",
                "Claude Code komutlarƒ±nƒ±n doƒüru formatƒ±nƒ± kullan",
                "Export fonksiyonlarƒ±nƒ± Claude Code uyumlu hale getir"
            ])
        elif test_result.test_type == "gemini_enhanced_testing":
            suggestions.extend([
                "Gemini API key'ini kontrol et",
                "Gemini model response parsing'i d√ºzelt",
                "Test scenario generation logic'ini g√∂zden ge√ßir"
            ])
        elif test_result.test_type == "error_recovery_system":
            suggestions.extend([
                "Error detection algoritmasƒ±nƒ± iyile≈ütir",
                "Auto-fix mechanisms'leri implement et",
                "Error handling robustness'ƒ± artƒ±r"
            ])
        
        # Genel √∂neriler
        suggestions.extend([
            "Test case validation logic'ini g√∂zden ge√ßir",
            "Response parsing accuracy'sini artƒ±r",
            "Error logging mechanisms'leri ekle"
        ])
        
        return suggestions
    
    def generate_issue_reports(self):
        """Issue raporlarƒ±nƒ± ayrƒ± dosyaya kaydet"""
        if not self.issue_reports:
            print("‚úÖ No issues found!")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Issue raporlarƒ± i√ßin JSON dosyasƒ±
        issues_data = {
            "report_metadata": {
                "generation_time": datetime.now().isoformat(),
                "total_issues": len(self.issue_reports),
                "severity_breakdown": self.get_severity_breakdown(),
                "category_breakdown": self.get_category_breakdown()
            },
            "issues": [asdict(issue) for issue in self.issue_reports],
            "fix_recommendations": self.generate_global_fix_recommendations()
        }
        
        issues_file = f"issue_reports_{timestamp}.json"
        with open(issues_file, 'w', encoding='utf-8') as f:
            json.dump(issues_data, f, indent=2, ensure_ascii=False)
        
        # Issue Summary dosyasƒ± (Claude Code i√ßin)
        summary_file = f"issue_summary_{timestamp}.md"
        self.create_issue_summary_markdown(summary_file)
        
        print(f"\nüìã ISSUE REPORTS GENERATED")
        print("=" * 50)
        print(f"üìÅ Detailed Issues: {issues_file}")
        print(f"üìÑ Summary Report: {summary_file}")
        print(f"üö® Total Issues: {len(self.issue_reports)}")
        print(f"‚ö†Ô∏è Critical Issues: {len([i for i in self.issue_reports if i.severity == 'CRITICAL'])}")
    
    def get_severity_breakdown(self) -> Dict[str, int]:
        """Issue severity breakdown"""
        breakdown = {"CRITICAL": 0, "HIGH": 0, "MEDIUM": 0, "LOW": 0}
        for issue in self.issue_reports:
            breakdown[issue.severity] = breakdown.get(issue.severity, 0) + 1
        return breakdown
    
    def get_category_breakdown(self) -> Dict[str, int]:
        """Issue category breakdown"""
        breakdown = {}
        for issue in self.issue_reports:
            breakdown[issue.category] = breakdown.get(issue.category, 0) + 1
        return breakdown
    
    def generate_global_fix_recommendations(self) -> List[str]:
        """Global d√ºzeltme √∂nerileri"""
        return [
            "Claude Code integration'ƒ± i√ßin API wrapper'larƒ± geli≈ütir",
            "Gemini response parsing'i i√ßin robust error handling ekle",
            "Test evaluation criteria'larƒ±nƒ± daha spesifik hale getir",
            "Automated fix suggestions i√ßin AI model entegrasyonu ekle",
            "Real-time issue tracking dashboard olu≈ütur"
        ]
    
    def create_issue_summary_markdown(self, filename: str):
        """Claude Code i√ßin markdown issue summary'si olu≈ütur"""
        content = f"""# üö® Issue Report Summary
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üìä Overview
- **Total Issues:** {len(self.issue_reports)}
- **Critical Issues:** {len([i for i in self.issue_reports if i.severity == 'CRITICAL'])}
- **High Priority Issues:** {len([i for i in self.issue_reports if i.severity == 'HIGH'])}

## üéØ Priority Issues

"""
        
        # Critical ve High priority issue'larƒ± listele
        priority_issues = [i for i in self.issue_reports if i.severity in ['CRITICAL', 'HIGH']]
        for issue in priority_issues[:5]:  # ƒ∞lk 5 priority issue
            content += f"""### {issue.severity} - {issue.title}
- **Category:** {issue.category}
- **Input:** `{issue.test_input}`
- **Expected:** {issue.expected_behavior}
- **Actual:** {issue.actual_behavior}
- **Suggestions:** {', '.join(issue.suggested_fixes[:2])}

"""
        
        content += f"""## üîß Claude Code Fix Commands

```bash
# Analyze this issue report with Claude Code
claude-code analyze {filename}

# Get specific fix suggestions
claude-code fix --category="{self.issue_reports[0].category if self.issue_reports else 'general'}"

# Run automated tests after fixes
python tools/advanced_test_categories.py --category=all
```

## üìà Next Steps
1. Review critical issues first
2. Implement suggested fixes
3. Re-run tests to verify fixes
4. Update test cases based on findings
"""
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def export_claude_integration_data(self):
        """Claude Code entegrasyonu i√ßin veri export et"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        claude_data = {
            "claude_integration": {
                "export_time": datetime.now().isoformat(),
                "test_results_summary": {
                    "total_tests": len(self.test_results),
                    "passed_tests": sum(1 for r in self.test_results if r.success),
                    "failed_tests": sum(1 for r in self.test_results if not r.success),
                    "success_rate": (sum(1 for r in self.test_results if r.success) / len(self.test_results)) * 100 if self.test_results else 0
                },
                "issue_analysis": {
                    "total_issues": len(self.issue_reports),
                    "by_severity": self.get_severity_breakdown(),
                    "by_category": self.get_category_breakdown()
                },
                "claude_commands": self.generate_claude_commands(),
                "analysis_prompts": [
                    "Analyze the failed test patterns and identify root causes",
                    "Suggest code improvements based on test failures",
                    "Review test case coverage and recommend additional scenarios",
                    "Optimize performance based on response time analysis",
                    "Identify security issues from test results"
                ]
            }
        }
        
        claude_file = f"claude_integration_{timestamp}.json"
        with open(claude_file, 'w', encoding='utf-8') as f:
            json.dump(claude_data, f, indent=2, ensure_ascii=False)
        
        print(f"üß† Claude Code integration data exported: {claude_file}")
        return claude_file
    
    def generate_claude_commands(self) -> List[str]:
        """Claude Code komutlarƒ± olu≈ütur"""
        commands = [
            "claude-code analyze tools/terminal_agent.py",
            "claude-code review --focus=error-handling",
            "claude-code optimize --target=response-time",
            "claude-code test --coverage=advanced-categories"
        ]
        
        # Issue'lara g√∂re √∂zel komutlar
        if any(i.category == "claude_code_integration" for i in self.issue_reports):
            commands.append("claude-code fix --integration-issues")
        
        if any(i.category == "security_analysis" for i in self.issue_reports):
            commands.append("claude-code security-scan")
        
        return commands
    
    def create_claude_fix_commands(self) -> str:
        """Claude Code fix komutlarƒ± olu≈ütur"""
        fix_script = f"""#!/bin/bash
# üîß CLAUDE CODE AUTOMATED FIX SCRIPT
# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

echo "üß† Starting Claude Code automated fixes..."

# Analyze current issues
echo "üìä Analyzing issues..."
"""

        for issue in self.issue_reports[:3]:  # ƒ∞lk 3 kritik issue
            fix_script += f"""
# Fix for: {issue.title}
echo "üîß Fixing: {issue.title}"
# claude-code fix --issue="{issue.issue_id}" --category="{issue.category}"
"""
        
        fix_script += """
# Re-run tests to verify fixes
echo "üß™ Running verification tests..."
python tools/advanced_test_categories.py --verify-fixes

echo "‚úÖ Claude Code fixes completed!"
"""
        
        script_file = f"claude_fixes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sh"
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(fix_script)
        
        os.chmod(script_file, 0o755)  # Make executable
        
        print(f"üîß Claude fix script created: {script_file}")
        return script_file

def main():
    """Ana test sistemi"""
    print("üß™ ADVANCED TEST CATEGORIES SYSTEM")
    print("üéØ Claude Code Integration + Gemini Enhanced Testing")
    print("=" * 80)
    
    try:
        # Test sistemini ba≈ülat
        test_system = AdvancedTestCategoriesSystem()
        
        # T√ºm kategorileri test et
        fix_script = test_system.run_advanced_category_tests()
        
        print(f"\nüéâ ADVANCED TESTING COMPLETED!")
        print(f"üîß Fix script: {fix_script}")
        print(f"üìã Issue reports generated in separate files")
        print(f"üß† Ready for Claude Code analysis and fixes")
        
        return 0
        
    except Exception as e:
        print(f"\n‚ùå ADVANCED TESTING FAILED!")
        print(f"üö® Error: {str(e)}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())